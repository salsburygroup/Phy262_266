{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will build on our clustering work from last time, and explore various machine learning techniques to look at our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1:Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the data as before, so import it, and display the corner plot and verify from your lab report that it looks the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data; no need to plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have found that Kmean clustering into 6 clusters gave the optimal silhoutte score, so cluster the data into 6 clusters. No plotting is needed, but the cluster labels need to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster the data; no need to plot. save the cluster labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Decision Tree modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of machine learning is to devise training and test sets. As the names suggests you use the training set to find your model, and then you test the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, cluster_train, cluster_test = train_test_split(data, cluster_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to train our model. We are doing to do decision trees first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the Decision Tree Classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the classifier on the training data\n",
    "clf.fit(data_train, cluster_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model that has been trained, we need to test the model on the data that the model was not trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict the Cluster_Labels for the test set\n",
    "cluster_pred = clf.predict(data_test)\n",
    "\n",
    "# Calculate the accuracy of the cluster predictions\n",
    "accuracy = accuracy_score(cluster_test, cluster_pred)\n",
    "print(f\"Model Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy should be pretty good; this is only 5D data\n",
    "Now let's visualize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "class_names = [\"Cl0\", \"Cl1\", \"Cl2\", \"Cl3\", \"Cl4\", \"Cl5\"]\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, filled=True, feature_names=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'], class_names=class_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting plot is likely impossible to read. Let's make it actually readable, by looking at just the first few layers.We will also save a higher res version of the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "class_names = [\"Cl0\", \"Cl1\", \"Cl2\", \"Cl3\", \"Cl4\", \"Cl5\"]\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, filled=True, feature_names=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'], class_names=class_names, max_depth=2)\n",
    "plt.savefig('decision_tree_high_res_depth2.png', format='png', dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot should now be readable, and let's interpert it. The purpose of this type of analysis is to find criteria that will cleanly separate out all the different clusters. This can rarely be done perfectly, but let's look at how this is done. Each box (aka node) should have five lines. In my analysis, the top box said:\n",
    "\n",
    "PC1 <= 58.374. This is the single decision that best separates out the data to the next level of boxes. Data for which this is true goes to the left, data for which this is false goes to the right.\n",
    "\n",
    "gini =0.812. This is how \"pure\" the node is. It is 0 if all the data at that node is in a single cluster. For six clusters, the value would be 0.8333 if the data was split evenly, and it's not quite that high.\n",
    "\n",
    "samples = 32000 That is how many data points there are; this is 80% of the total data points, as 20% were withheld to test on.\n",
    "\n",
    "value = [ 6880, 3569, 7958, 3965, 6663, 2965] this is how the data at the node is distributued among the different clusters, which for the top node is just the clustering distribution among the training set.\n",
    "\n",
    "class = Cl2 This is largest cluster in that node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1: How close is your top box to mine? Two of these lines might vary since the model was trained on a randomly selected 80% of the data.\n",
    "\n",
    "Question 2: Are there nodes that are fairly pure (gini index < 0.16 > for example), and that contain most of a particular cluster?\n",
    "\n",
    "If so, which criteria were made to reach those nodes (remember if the node is to the right of a decision, then the decision was false, so the criteria needs to be reversed. )\n",
    "\n",
    " What % of the dominate cluster is in these nodes, that is compared to the original population what % of that cluster is in a particular node that you identified? This last question is important because the gini index tells you if a node is largely in a single cluster, but it doesn't tell you how much of the original cluster is accounted for in a node.\n",
    "\n",
    "Exercise 1: Extend out the depth of the decision tree and see what happens. When do you get to the point where you can identify decisions that will classify most of each cluster into a single relatively pure node? Note, different clusters may need different numbers of decisions. What are the decision for each cluster, the gini index, and what % of each cluster makes itn into the nodes you identify. You will need to change the names of the png files and zoom in on them in file tree rather in the note book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for different depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 4: Random Forest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that might have come to mind when you were working, is that this tree was trained on 80% of the data randomly selected; what happens if a different set of 80% of the data was selected? Well, that is a good question, and you can get a sense of this from question one, or by comparing your results with your classmates. However, there might be a more efficient way of doing this. There is the \"Random Forest model\". This is as the name suggests one where you compute many decision trees and find the consensus (mode) result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Assuming X is your feature set and y is your target variable\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Split data into training and testing set\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m data_train, data_test, cluster_train, cluster_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdata\u001b[49m, cluster_labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize the model\u001b[39;00m\n\u001b[1;32m     11\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \u001b[38;5;66;03m# 10 trees in the forest\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X is your feature set and y is your target variable\n",
    "# Split data into training and testing set\n",
    "data_train, data_test, cluster_train, cluster_test = train_test_split(data, cluster_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the model\n",
    "rf = RandomForestClassifier(n_estimators=10, random_state=42)  # 10 trees in the forest\n",
    "\n",
    "# Train the model\n",
    "rf.fit(data_train, cluster_train)\n",
    "\n",
    "# Make predictions\n",
    "cluster_pred = rf.predict(data_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {accuracy_score(cluster_test, cluster_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "One issue with random forest modeling is that it uses the consensus results from all the trees to classify data, so you can't visualize and extract precise decisions readily. Whether precise decisions or higher accuracy is more important, will depend on what questions you ask asking. You can plot individial trees to get a sense of how they are different, or you can look for important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Convert the importances into a DataFrame\n",
    "feature_importance_df = pd.DataFrame({'Feature': ['PC1', 'PC2', 'PC3', 'PC4', 'PC5'], 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature on top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot might look kind of lame, and it is not as pretty as many figures you have made. However, keep in mind this is data with only five features, but it does show something interesting. The importance of the features does not simply decline as the PC number increases. This can be a surprise, the PCs account for less and less variance in the structural data as the number increases, yet this is saying for accounting for cluster variation, that PC3 is nearly as important as PC1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2:  What happens to the accuracy and feature importance if you do the random forest classifier for 1, 2, 10, 100 and 1000 trees, be quantitative? Keep in mind this data was pretty-well modeled with a single tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at different trees. Obviously you cannot look at all 1000, but here is how we could look at the 10th tree (numbering starts at 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Select a single tree from the random forest\n",
    "single_tree = rf.estimators_[9]\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(single_tree, feature_names=['PC1', 'PC2', 'PC3', 'PC4', 'PC5'], class_names=class_names, filled=True, max_depth=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10+20+30)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3: Look at 5 different trees. How are they different? In particular, how is the first decision different? Are there different low gini nodes that account for a large fraction of a particular cluster?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
